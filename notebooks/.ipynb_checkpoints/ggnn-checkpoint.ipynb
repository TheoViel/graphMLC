{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/theo/MVA/graph_mlc/src\n"
     ]
    }
   ],
   "source": [
    "cd ../src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import *\n",
    "from params import *\n",
    "from imports import *\n",
    "\n",
    "from data.dataset import *\n",
    "from data.transforms import *\n",
    "\n",
    "from model_zoo.common import *\n",
    "from model_zoo.ggnn import *\n",
    "\n",
    "from training.train import *\n",
    "from training.freezing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPUTE_A = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_dataset = MLCDataset(TRAINVAL_IMGS, \n",
    "                              transforms=get_transfos(size=IMG_SIZE),\n",
    "                              img_path=IMG_PATH,\n",
    "                              annotation_path=ANNOTATION_PATH\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MLCDataset(TEST_IMGS, \n",
    "                          transforms=get_transfos(test=True, size=IMG_SIZE),\n",
    "                          img_path=IMG_PATH,\n",
    "                          annotation_path=ANNOTATION_PATH\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Genome Relationship Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_KEPT_ITEMS = 300\n",
    "NB_KEPT_PREDICATES = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES_ALIAS = [\n",
    "        'airplane', 'bicycle', 'bird', 'boat',\n",
    "        'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "        'cow', 'table', 'dog', 'horse',\n",
    "        'motorcycle', 'person', 'plant',\n",
    "        'sheep', 'couch', 'train',\n",
    "        'tv'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_relationships(data):\n",
    "    objects = []\n",
    "    predicates = []\n",
    "    subjects = []\n",
    "    for d in tqdm(data):\n",
    "        for r in d['relationships']:\n",
    "            predicates.append(r['predicate'].lower())\n",
    "            try:\n",
    "                objects.append(r['object']['name'])\n",
    "            except:\n",
    "                objects.append(r['object']['names'][0])\n",
    "            try:\n",
    "                subjects.append(r['subject']['name'])\n",
    "            except:\n",
    "                subjects.append(r['subject']['names'][0])\n",
    "    return objects, predicates, subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e96f5ba51d4458e924715620ca44341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=108077), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if COMPUTE_A:\n",
    "    with open('../input/wordnet/relationships.json', 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        json_file.close\n",
    "        \n",
    "    objects, predicates, subjects = extract_relationships(data)\n",
    "    \n",
    "    count = Counter(objects + subjects)\n",
    "    count_p = Counter(predicates)\n",
    "    \n",
    "    sorted_count = np.array(sorted(count.items(), key=operator.itemgetter(1)))[::-1]\n",
    "    sorted_count_p = np.array(sorted(count_p.items(), key=operator.itemgetter(1)))[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMPUTE_A:\n",
    "    kept_items = sorted_count[:NB_KEPT_ITEMS, 0]\n",
    "    kept_items = CLASSES_ALIAS + [item for item in kept_items if item not in CLASSES_ALIAS]\n",
    "    kept_items = kept_items[:NB_KEPT_ITEMS]\n",
    "    \n",
    "    kept_predicates = list(sorted_count_p[:NB_KEPT_PREDICATES, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "921fef0ea93d40278bef4f79291b9c55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if COMPUTE_A:\n",
    "    objects_new = []\n",
    "    predicates_new = []\n",
    "    subjects_new = []\n",
    "\n",
    "    for o, p, s in tqdm(zip(objects, predicates, subjects)):\n",
    "        if o in kept_items and s in kept_items and p in kept_predicates:\n",
    "            objects_new.append(o)\n",
    "            predicates_new.append(p)\n",
    "            subjects_new.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e345c73a20864465aae14a21e32338d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if COMPUTE_A:\n",
    "    A_in = np.zeros((NB_KEPT_PREDICATES, NB_KEPT_ITEMS, NB_KEPT_ITEMS), dtype=np.int32)\n",
    "    A_out = np.zeros((NB_KEPT_PREDICATES, NB_KEPT_ITEMS, NB_KEPT_ITEMS), dtype=np.int32)\n",
    "\n",
    "    for o, p, s in tqdm(zip(objects_new, predicates_new, subjects_new)):\n",
    "        A_in[kept_predicates.index(p), kept_items.index(o), kept_items.index(s)] = 1\n",
    "        A_out[kept_predicates.index(p), kept_items.index(s), kept_items.index(o)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMPUTE_A:\n",
    "    np.save('../output/A_in.npy', A_in)\n",
    "    np.save('../output/A_out.npy', A_out)\n",
    "else:\n",
    "    A_in = np.load('../output/A_in.npy')\n",
    "    A_out = np.load('../output/A_out.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_in = A_in.mean(0, keepdims=True)\n",
    "A_out = A_out.mean(0, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = 0.1\n",
    "THRESHOLD = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_in = A_in / A_in.max()\n",
    "A_out = A_out / A_out.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_in = threshold_and_smooth_matrix(A_in[0], t=THRESHOLD, p=P)[np.newaxis, :, :]\n",
    "A_out = threshold_and_smooth_matrix(A_out[0], t=THRESHOLD, p=P)[np.newaxis, :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ggnn(backbone, train_dataset, val_dataset, \n",
    "                A_in, A_out, num_classes=20, use_ggnn=True,\n",
    "                test_dataset=None, cp=False, model_name='model', threshold=0.5):\n",
    "    \n",
    "    seed_everything(SEED)\n",
    "    \n",
    "    model = GGNNClassifier(backbone, num_classes, A_in, A_out, ggnn_dim=10, time_steps=3, use_ggnn=use_ggnn).cuda()\n",
    "\n",
    "    print('\\n- Training logits only : ')\n",
    "\n",
    "    freeze(model)\n",
    "    for layer in ['out', 'ggnn', 'logits', 'bias_node']:\n",
    "        unfreeze_layer(model, layer)\n",
    "\n",
    "    n_parameters = count_parameters(model)\n",
    "    print(f'    -> {n_parameters} trainable parameters\\n')\n",
    "\n",
    "    fit(model, train_dataset, val_dataset, epochs=3, batch_size=32, warmup_prop=0, lr=1e-3, min_lr=1e-4,\n",
    "        verbose=1, verbose_eval=1, cp=False, model_name='model')\n",
    "\n",
    "    print('\\n- Training all layers: ')\n",
    "\n",
    "    if backbone == 'resnet34':\n",
    "        unfreeze(model)\n",
    "    else:\n",
    "        unfreeze_layer(model, 'layer4')\n",
    "        \n",
    "    n_parameters = count_parameters(model)\n",
    "    print(f'    -> {n_parameters} trainable parameters\\n')\n",
    "\n",
    "    fit(model, train_dataset, val_dataset, epochs=5, batch_size=32, warmup_prop=0, lr=1e-4, min_lr=1e-6,\n",
    "        verbose=1, verbose_eval=1, cp=cp, model_name=model_name)\n",
    "\n",
    "    print('\\n- Evaluating: \\n')\n",
    "\n",
    "    if cp:\n",
    "        load_model_weights(model, model_name, verbose=1)\n",
    "        \n",
    "    pred_val = predict_voc(model, val_dataset)\n",
    "    print(f' - Scored {voc12_mAP(pred_val) :.3f} on validation data')\n",
    "    \n",
    "    if test_dataset is not None:\n",
    "        pred_test = predict_voc(model, test_dataset)\n",
    "        print(f' - Scored {voc12_mAP(pred_test) :.3f} on test data\\n')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = 'resnet34'\n",
    "# backbone = 'resnet101'\n",
    "# backbone = 'resnext101'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1, 0.1)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P, THRESHOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Training logits only : \n",
      "    -> 221040 trainable parameters\n",
      "\n",
      "Epoch 1/3 \t lr=1.0e-03 \t t=14s \t loss=0.168 \t mAP=0.788 \t val_loss=0.104 \t \n",
      "Epoch 2/3 \t lr=5.5e-04 \t t=14s \t loss=0.112 \t mAP=0.811 \t val_loss=0.092 \t \n",
      "Epoch 3/3 \t lr=1.0e-04 \t t=14s \t loss=0.096 \t mAP=0.820 \t val_loss=0.088 \t \n",
      "\n",
      "- Training all layers: \n",
      "    -> 21505712 trainable parameters\n",
      "\n",
      "Epoch 1/5 \t lr=1.0e-04 \t t=20s \t loss=0.097 \t mAP=0.846 \t val_loss=0.083 \t \n",
      "Epoch 2/5 \t lr=8.6e-05 \t t=20s \t loss=0.067 \t mAP=0.854 \t val_loss=0.084 \t \n",
      "Epoch 3/5 \t lr=5.1e-05 \t t=20s \t loss=0.049 \t mAP=0.864 \t val_loss=0.077 \t \n",
      "Epoch 4/5 \t lr=1.5e-05 \t t=20s \t loss=0.037 \t mAP=0.868 \t val_loss=0.076 \t \n",
      "Epoch 5/5 \t lr=1.0e-06 \t t=20s \t loss=0.033 \t mAP=0.868 \t val_loss=0.075 \t \n",
      "\n",
      "- Evaluating: \n",
      "\n",
      " - Scored 0.868 on validation data\n"
     ]
    }
   ],
   "source": [
    "model = train_ggnn(backbone, trainval_dataset, test_dataset, A_in, A_out, num_classes=NUM_CLASSES, model_name=backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
