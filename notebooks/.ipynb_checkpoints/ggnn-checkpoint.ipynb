{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/theo/MVA/graph_mlc/src\n"
     ]
    }
   ],
   "source": [
    "cd ../src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import *\n",
    "from params import *\n",
    "from imports import *\n",
    "\n",
    "from data.dataset import *\n",
    "from data.transforms import *\n",
    "\n",
    "from model_zoo.common import *\n",
    "from model_zoo.ggnn import *\n",
    "\n",
    "from training.train import *\n",
    "from training.freezing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPUTE_A = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_dataset = MLCDataset(TRAINVAL_IMGS, \n",
    "                              transforms=get_transfos(size=IMG_SIZE),\n",
    "                              img_path=IMG_PATH,\n",
    "                              annotation_path=ANNOTATION_PATH\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MLCDataset(TEST_IMGS, \n",
    "                          transforms=get_transfos(test=True, size=IMG_SIZE),\n",
    "                          img_path=IMG_PATH,\n",
    "                          annotation_path=ANNOTATION_PATH\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Genome Relationship Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_KEPT_ITEMS = 300\n",
    "NB_KEPT_PREDICATES = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES_ALIAS = [\n",
    "        'airplane', 'bicycle', 'bird', 'boat',\n",
    "        'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "        'cow', 'table', 'dog', 'horse',\n",
    "        'motorcycle', 'person', 'plant',\n",
    "        'sheep', 'couch', 'train',\n",
    "        'tv'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_relationships(data):\n",
    "    objects = []\n",
    "    predicates = []\n",
    "    subjects = []\n",
    "    for d in tqdm(data):\n",
    "        for r in d['relationships']:\n",
    "            predicates.append(r['predicate'].lower())\n",
    "            try:\n",
    "                objects.append(r['object']['name'])\n",
    "            except:\n",
    "                objects.append(r['object']['names'][0])\n",
    "            try:\n",
    "                subjects.append(r['subject']['name'])\n",
    "            except:\n",
    "                subjects.append(r['subject']['names'][0])\n",
    "    return objects, predicates, subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9165256e619f4d0cb975e8ae4ad45669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=108077), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if COMPUTE_A:\n",
    "    with open(VISUAL_GENOME_PATH + 'relationships.json', 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        json_file.close\n",
    "        \n",
    "    objects, predicates, subjects = extract_relationships(data)\n",
    "    \n",
    "    count = Counter(objects + subjects)\n",
    "    count_p = Counter(predicates)\n",
    "    \n",
    "    sorted_count = np.array(sorted(count.items(), key=operator.itemgetter(1)))[::-1]\n",
    "    sorted_count_p = np.array(sorted(count_p.items(), key=operator.itemgetter(1)))[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMPUTE_A:\n",
    "    kept_items = sorted_count[:NB_KEPT_ITEMS, 0]\n",
    "    kept_items = CLASSES_ALIAS + [item for item in kept_items if item not in CLASSES_ALIAS]\n",
    "    kept_items = kept_items[:NB_KEPT_ITEMS]\n",
    "    \n",
    "    kept_predicates = list(sorted_count_p[:NB_KEPT_PREDICATES, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8996a1048ddc46c19f7b88cca087b055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if COMPUTE_A:\n",
    "    objects_new = []\n",
    "    predicates_new = []\n",
    "    subjects_new = []\n",
    "\n",
    "    for o, p, s in tqdm(zip(objects, predicates, subjects)):\n",
    "        if o in kept_items and s in kept_items and p in kept_predicates:\n",
    "            objects_new.append(o)\n",
    "            predicates_new.append(p)\n",
    "            subjects_new.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab555a0bf839456eadc035350f4708fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if COMPUTE_A:\n",
    "    A_in = np.zeros((NB_KEPT_PREDICATES, NB_KEPT_ITEMS, NB_KEPT_ITEMS), dtype=np.int32)\n",
    "    A_out = np.zeros((NB_KEPT_PREDICATES, NB_KEPT_ITEMS, NB_KEPT_ITEMS), dtype=np.int32)\n",
    "\n",
    "    for o, p, s in tqdm(zip(objects_new, predicates_new, subjects_new)):\n",
    "        A_in[kept_predicates.index(p), kept_items.index(o), kept_items.index(s)] = 1\n",
    "        A_out[kept_predicates.index(p), kept_items.index(s), kept_items.index(o)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMPUTE_A:\n",
    "    np.save('../output/A_in.npy', A_in)\n",
    "    np.save('../output/A_out.npy', A_out)\n",
    "else:\n",
    "    A_in = np.load('../output/A_in.npy')\n",
    "    A_out = np.load('../output/A_out.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_in = A_in.mean(0, keepdims=True)\n",
    "A_out = A_out.mean(0, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = 0.1\n",
    "THRESHOLD = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_in = A_in / A_in.max()\n",
    "A_out = A_out / A_out.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_in = threshold_and_reweight_matrix(A_in[0], t=THRESHOLD, p=P)[np.newaxis, :, :]\n",
    "A_out = threshold_and_reweight_matrix(A_out[0], t=THRESHOLD, p=P)[np.newaxis, :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ggnn(backbone, train_dataset, val_dataset, \n",
    "                A_in, A_out, num_classes=20, use_ggnn=True,\n",
    "                test_dataset=None, cp=False, model_name='model', threshold=0.5):\n",
    "    \n",
    "    seed_everything(SEED)\n",
    "    \n",
    "    model = GGNNClassifier(backbone, num_classes, A_in, A_out, ggnn_dim=10, time_steps=3, use_ggnn=use_ggnn).cuda()\n",
    "\n",
    "    print('\\n- Training logits only : ')\n",
    "\n",
    "    freeze(model)\n",
    "    for layer in ['out', 'ggnn', 'logits', 'bias_node']:\n",
    "        unfreeze_layer(model, layer)\n",
    "\n",
    "    n_parameters = count_parameters(model)\n",
    "    print(f'    -> {n_parameters} trainable parameters\\n')\n",
    "\n",
    "    fit(model, train_dataset, val_dataset, epochs=3, batch_size=32, warmup_prop=0, lr=1e-3, min_lr=1e-4,\n",
    "        verbose=1, verbose_eval=1, cp=False, model_name='model')\n",
    "\n",
    "    print('\\n- Training all layers: ')\n",
    "\n",
    "    if backbone == 'resnet34':\n",
    "        unfreeze(model)\n",
    "    else:\n",
    "        unfreeze_layer(model, 'layer4')\n",
    "        \n",
    "    n_parameters = count_parameters(model)\n",
    "    print(f'    -> {n_parameters} trainable parameters\\n')\n",
    "\n",
    "    batch_size = 32 if IMG_SIZE == 224 else 8\n",
    "    fit(model, train_dataset, val_dataset, epochs=5, batch_size=batch_size, warmup_prop=0, lr=1e-4, min_lr=1e-6,\n",
    "        verbose=1, verbose_eval=1, cp=cp, model_name=model_name)\n",
    "\n",
    "    print('\\n- Evaluating: \\n')\n",
    "\n",
    "    if cp:\n",
    "        load_model_weights(model, model_name, verbose=1)\n",
    "        \n",
    "    pred_val = predict_voc(model, val_dataset)\n",
    "    print(f' - Scored {voc12_mAP(pred_val) :.3f} on validation data')\n",
    "    aps = voc12_mAP(pred_val, return_aps=True)\n",
    "    \n",
    "    if test_dataset is not None:\n",
    "        pred_test = predict_voc(model, test_dataset)\n",
    "        print(f' - Scored {voc12_mAP(pred_test) :.3f} on test data\\n')\n",
    "    \n",
    "    return model, aps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = 'resnet34'\n",
    "# backbone = 'resnet101'\n",
    "# backbone = 'resnext101'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Training logits only : \n",
      "    -> 221040 trainable parameters\n",
      "\n",
      "Epoch 1/3 \t lr=1.0e-03 \t t=76s \t loss=0.203 \t mAP=0.749 \t val_loss=0.123 \t \n",
      "Epoch 2/3 \t lr=5.5e-04 \t t=76s \t loss=0.116 \t mAP=0.799 \t val_loss=0.096 \t \n",
      "Epoch 3/3 \t lr=1.0e-04 \t t=76s \t loss=0.094 \t mAP=0.816 \t val_loss=0.088 \t \n",
      "\n",
      "- Training all layers: \n",
      "    -> 21505712 trainable parameters\n",
      "\n",
      "Epoch 1/5 \t lr=1.0e-04 \t t=105s \t loss=0.079 \t mAP=0.898 \t val_loss=0.066 \t \n",
      "Epoch 2/5 \t lr=8.6e-05 \t t=105s \t loss=0.050 \t mAP=0.908 \t val_loss=0.065 \t \n",
      "Epoch 3/5 \t lr=5.1e-05 \t t=105s \t loss=0.035 \t mAP=0.918 \t val_loss=0.055 \t \n",
      "Epoch 4/5 \t lr=1.5e-05 \t t=105s \t loss=0.026 \t mAP=0.921 \t val_loss=0.053 \t \n",
      "Epoch 5/5 \t lr=1.0e-06 \t t=105s \t loss=0.022 \t mAP=0.921 \t val_loss=0.053 \t \n",
      "\n",
      "- Evaluating: \n",
      "\n",
      " - Scored 0.921 on validation data\n"
     ]
    }
   ],
   "source": [
    "model, aps = train_ggnn(backbone, trainval_dataset, test_dataset, A_in, A_out, num_classes=NUM_CLASSES, model_name=backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../output/aps_ggnn_resnet34_576.npy', np.array(aps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = 'resnext101'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Training logits only : \n",
      "    -> 681840 trainable parameters\n",
      "\n",
      "Epoch 1/3 \t lr=1.0e-03 \t t=46s \t loss=0.305 \t mAP=0.898 \t val_loss=0.071 \t \n",
      "Epoch 2/3 \t lr=5.5e-04 \t t=46s \t loss=0.075 \t mAP=0.907 \t val_loss=0.067 \t \n",
      "Epoch 3/3 \t lr=1.0e-04 \t t=47s \t loss=0.059 \t mAP=0.911 \t val_loss=0.058 \t \n",
      "\n",
      "- Training all layers: \n",
      "    -> 29427568 trainable parameters\n",
      "\n",
      "Epoch 1/5 \t lr=1.0e-04 \t t=52s \t loss=0.066 \t mAP=0.926 \t val_loss=0.054 \t \n",
      "Epoch 2/5 \t lr=8.6e-05 \t t=52s \t loss=0.040 \t mAP=0.928 \t val_loss=0.056 \t \n",
      "Epoch 3/5 \t lr=5.1e-05 \t t=52s \t loss=0.025 \t mAP=0.932 \t val_loss=0.052 \t \n",
      "Epoch 4/5 \t lr=1.5e-05 \t t=52s \t loss=0.015 \t mAP=0.935 \t val_loss=0.051 \t \n",
      "Epoch 5/5 \t lr=1.0e-06 \t t=52s \t loss=0.011 \t mAP=0.935 \t val_loss=0.051 \t \n",
      "\n",
      "- Evaluating: \n",
      "\n",
      " - Scored 0.935 on validation data\n"
     ]
    }
   ],
   "source": [
    "model = train_ggnn(backbone, trainval_dataset, test_dataset, A_in, A_out, num_classes=NUM_CLASSES, model_name=backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
